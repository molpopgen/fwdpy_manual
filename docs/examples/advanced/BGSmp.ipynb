{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    ".. _BGS_multiprocessing:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced example: background selection (revisited)\n",
    "\n",
    "This is the same background selection simulation as in the previous example, but with the following change to the implementation details:\n",
    "\n",
    "* We change the nature of the parallelism.  The previous example uses fwdpy to run 40 simulations at a time, process them, and then repeat the process 25 times, doing all of the analysis in-memory.  Here, we use the multiprocessing module to spawn 40 separate Python processes.  Each process runs 25 simulations and records the summary statistics.  At the end of the 25 replicates, the data are written to an SQLite database and get the mean values via an SQL query, which is out-of-memory.\n",
    "\n",
    "The purpose of this example is to show that there are multiple ways to do things in terms of how to use parallel processing to perform simulations.  Further, the technique of writing results to an SQLite database is very powerful as it allows many analyses (\"aggregations\") to be done without loading all of your simulation results into RAM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Use Python 3's print a a function.\n",
    "#This future-proofs the code in the notebook\n",
    "from __future__ import print_function\n",
    "#Import fwdpy.  Give it a shorter name\n",
    "import fwdpy as fp\n",
    "##Other libs we need\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import os\n",
    "import sqlite3\n",
    "import multiprocessing as mp\n",
    "import libsequence.polytable as polyt\n",
    "import libsequence.summstats as sstats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the function that we will run in separate Python processes\n",
    "\n",
    "The details of setting up the simulation are identical to the prevous BGS example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def simulate_async(args):\n",
    "    \"\"\"\n",
    "    This function will be run in a separate process\n",
    "    using the multiprocessing module.  Its argument \n",
    "    list is a tuple.\n",
    "\n",
    "    \"\"\"\n",
    "    #Assign names to the tuple values\n",
    "    seed,dbname,tablename = args\n",
    "    \n",
    "    # Where neutral mutations occur:\n",
    "    nregions = [fp.Region(beg=0,end=1,weight=1)]\n",
    "\n",
    "    # Where selected mutations occur:\n",
    "    sregions = [fp.ConstantS(beg=-1,end=0,weight=1,s=-0.05,h=1),\n",
    "                fp.ConstantS(beg=1,end=2,weight=1,s=-0.05,h=1)]\n",
    "\n",
    "    # Recombination:\n",
    "    recregions = [fp.Region(beg=-1,end=2,weight=1)]\n",
    "\n",
    "    #Population size\n",
    "    N=1000\n",
    "    #We'll evolve for 10N generations.\n",
    "    #nlist is a list of population sizes over time.\n",
    "    #len(nlist) is the length of the simulation\n",
    "    #We use numpy arrays for speed and optimised RAM\n",
    "    #use.  Note the dtype=np.uint32, which means 32-bit\n",
    "    #unsigned integer. Failure to use this type will\n",
    "    #cause a run-time error.\n",
    "    nlist = np.array([N]*(10*N),dtype=np.uint32)\n",
    "\n",
    "    #Initalize a random number generator with seed value of 101\n",
    "    rng = fp.GSLrng(seed)\n",
    "\n",
    "    summstats=[]\n",
    "    for replicate in range(0,25,1):\n",
    "        pops = fp.evolve_regions(rng,  \n",
    "                             1,       #Simulate only 1 population at a time     \n",
    "                             N,        \n",
    "                             nlist[0:],\n",
    "                             0.005,    \n",
    "                             0.01,     \n",
    "                             0.005,    \n",
    "                             nregions, \n",
    "                             sregions, \n",
    "                             recregions)\n",
    "        sample = fp.get_samples(rng,pops[0],20)\n",
    "        simdatasNeut = polyt.SimData(sample[0])\n",
    "        polySIMn = sstats.PolySIM(simdatasNeut)\n",
    "        ##Append stats into our growing DataFrame:\n",
    "        summstats.append({'thetapi':polySIMn.thetapi(),'npoly':polySIMn.numpoly(),'thetaw':polySIMn.thetaw()})\n",
    "    DF=pd.DataFrame(summstats)\n",
    "    con = sqlite3.connect(dbname)\n",
    "    DF.to_sql(tablename,con,if_exists='append',index=False)\n",
    "    con.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run the simulations\n",
    "\n",
    "The following block of code sets up a thread pool to run the above function using 40 separate processes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "if os.path.isfile('BGSmp.db'):\n",
    "    os.remove('BGSmp.db')\n",
    "np.random.seed(101)\n",
    "args=[(seed,'BGSmp.db','stats') for seed in np.random.randint(0,42000000,40)]\n",
    "#P a thread pool using the number of processors on your machine\n",
    "#If you have < 40 cores, it'll spawn new processes as old ones finish.\n",
    "#for i in args: simulate_async(i)\n",
    "P=mp.Pool() \n",
    "P.imap_unordered(simulate_async,args)\n",
    "P.close()\n",
    "P.join()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Getting the mean diversity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   avg(npoly)  avg(thetapi)  avg(thetaw)\n",
      "0       0.978      0.100195     0.275668\n"
     ]
    }
   ],
   "source": [
    "#open database connection:\n",
    "c=sqlite3.connect('BGSmp.db')\n",
    "#Get means for each column:\n",
    "x=pd.read_sql_query('select avg(npoly),avg(thetapi),avg(thetaw) from stats',c)\n",
    "c.close()\n",
    "os.remove('BGSmp.db')\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 'thetapi' record is our mean $\\pi$ from all of the simulations, and it is quite close to the theoretical value. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
